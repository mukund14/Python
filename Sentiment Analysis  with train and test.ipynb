{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re, math, collections, itertools\n",
    "import nltk, nltk.classify.util, nltk.metrics\n",
    "from nltk import bigrams \n",
    "from nltk.probability import ELEProbDist\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "from nltk.probability import FreqDist, ConditionalFreqDist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##f = open(\"sentitrain.txt\")\n",
    "#next = f.read(1)\n",
    "#while next != \"\":\n",
    "#    print(next)\n",
    "#    next = f.read(1)\n",
    "    \n",
    "train = pd.read_csv(\"sentitrain.txt\", sep='\\t', \n",
    "                  names = [\"Sentiment\", \"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets = []\n",
    "x=train[\"Text\"].str.split(\" \")\n",
    "\n",
    "tweets = []\n",
    "\n",
    "for (words, sentiment) in train.iteritems():\n",
    "\n",
    "    words_filtered = x\n",
    "    tweets.append((words_filtered, sentiment))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'samples'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-bebaabe2cc46>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#train_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNaiveBayesClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mText\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSentiment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mText\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mSentiment\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\mukun\\Anaconda2\\envs\\gl-env\\lib\\site-packages\\nltk\\classify\\naivebayes.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, label_probdist, feature_probdist)\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_label_probdist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_probdist\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feature_probdist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_probdist\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_probdist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\mukun\\Anaconda2\\envs\\gl-env\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2667\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2668\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2669\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2671\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'samples'"
     ]
    }
   ],
   "source": [
    "Text=tweets[1][0]\n",
    "Sentiment=tweets[0][1]\n",
    "train_data=pd.concat([Sentiment, Text], axis=1)\n",
    "train_data=train_data.sample(frac=0.2,random_state=200)\n",
    "Text=train_data.Text\n",
    "Sentiment=train_data.Sentiment\n",
    "train_data.head()\n",
    "#train_data\n",
    "train_data\n",
    "model=NaiveBayesClassifier(Text,Sentiment)\n",
    "model.fit(Text,Sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "       \n",
    "t = []  \n",
    "for a in Text:  \n",
    "        for b in Sentiment:  \n",
    "                t.append([a,b])  \n",
    "                \n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_words_in_tweets(t):\n",
    "\n",
    "    all_words = []\n",
    "    for (words, sentiment) in t:\n",
    "        all_words.extend(words)\n",
    "    return all_words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word_features(wordlist):\n",
    "    wordlist = nltk.FreqDist(wordlist)\n",
    "    word_features = wordlist.keys()\n",
    "    return word_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "word_features=get_word_features(get_words_in_tweets(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "    return features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_set = nltk.classify.apply_features(extract_features, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(labeled_featuresets, estimator=ELEProbDist):\n",
    "    # Create the P(label) distribution\n",
    "    label_probdist = estimator(label_freqdist)\n",
    "    # Create the P(fval|label, fname) distribution\n",
    "    feature_probdist = {}\n",
    "    return NaiveBayesClassifier(label_probdist, feature_probdist)\n",
    "\n",
    "    print label_probdist.prob('1')\n",
    "    print feature_probdist\n",
    "    print feature_probdist[('0', 'contains(best)')].prob(True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "     contains(Demons...) = True                0 : 1      =      1.0 : 1.0\n",
      "        contains(legacy) = True                0 : 1      =      1.0 : 1.0\n",
      "       contains(lately,) = True                0 : 1      =      1.0 : 1.0\n",
      "          contains(one.) = True                0 : 1      =      1.0 : 1.0\n",
      "            contains(et) = True                0 : 1      =      1.0 : 1.0\n",
      "          contains(hot.) = True                0 : 1      =      1.0 : 1.0\n",
      "         contains(Okay,) = True                0 : 1      =      1.0 : 1.0\n",
      "           contains(SAD) = True                0 : 1      =      1.0 : 1.0\n",
      "            contains(By) = True                0 : 1      =      1.0 : 1.0\n",
      "           contains(N'T) = True                0 : 1      =      1.0 : 1.0\n",
      "         contains(Hanks) = True                0 : 1      =      1.0 : 1.0\n",
      "      contains(interest) = True                0 : 1      =      1.0 : 1.0\n",
      "          contains(tell) = True                0 : 1      =      1.0 : 1.0\n",
      "       contains(looking) = True                0 : 1      =      1.0 : 1.0\n",
      "   contains(CODE!!!!...) = True                0 : 1      =      1.0 : 1.0\n",
      "          contains(lah.) = True                0 : 1      =      1.0 : 1.0\n",
      "          contains(hope) = True                0 : 1      =      1.0 : 1.0\n",
      "         contains(alarm) = True                0 : 1      =      1.0 : 1.0\n",
      "          contains(HAVE) = True                0 : 1      =      1.0 : 1.0\n",
      "          contains(Fire) = True                0 : 1      =      1.0 : 1.0\n",
      "        contains(Goblet) = True                0 : 1      =      1.0 : 1.0\n",
      "             contains(<) = True                0 : 1      =      1.0 : 1.0\n",
      "      contains(admiring) = True                0 : 1      =      1.0 : 1.0\n",
      "       contains(suppose) = True                0 : 1      =      1.0 : 1.0\n",
      "           contains(ask) = True                0 : 1      =      1.0 : 1.0\n",
      "            contains(3:) = True                0 : 1      =      1.0 : 1.0\n",
      "            contains(he) = True                0 : 1      =      1.0 : 1.0\n",
      "      contains(deserved) = True                0 : 1      =      1.0 : 1.0\n",
      "             contains(O) = True                0 : 1      =      1.0 : 1.0\n",
      "        contains(issues) = True                0 : 1      =      1.0 : 1.0\n",
      "          contains(EVER) = True                0 : 1      =      1.0 : 1.0\n",
      "          contains(rare) = True                0 : 1      =      1.0 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "print classifier.show_most_informative_features(32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "tweet1 = \"The movie sucks\"\n",
    "tweet2=\"Are you a millennial?  Tell us what tools you need and how you prefer to give to nonprofits like Abilities United\"\n",
    "tweet3=\"Volunteers Mukundan and Gautam working on art projects and social media.  You guys rock!\"\n",
    "tweet4=\"In honor of John Glenn, Abilities United's flag flys at half staff.  RIP John and thank you for taking us to the moon and back.\"\n",
    "print classifier.classify(extract_features(tweet1.split()))\n",
    "print classifier.classify(extract_features(tweet2.split()))\n",
    "print classifier.classify(extract_features(tweet3.split()))\n",
    "print classifier.classify(extract_features(tweet4.split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test=pd.read_csv(\"@AbilitiesUnited_tweets.csv\")\n",
    "x1=test[\"text\"][9]\n",
    "#classifier.classify(test.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classify(extract_features(x1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
